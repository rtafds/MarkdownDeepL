{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit\n",
    "import json\n",
    "import deepl\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_settings():\n",
    "    global master_data, translator\n",
    "    # デフォルト値\n",
    "\n",
    "    master_data = {\n",
    "        \"auth_key\": \"\",\n",
    "        \"source_lang\": \"EN\",\n",
    "        \"target_lang\": \"JA\"\n",
    "    }\n",
    "    try:\n",
    "        with open(\"config.json\") as fp:\n",
    "            update_data = json.load(fp)\n",
    "        for k, v in update_data.items():\n",
    "            master_data[k] = v\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def translate(source_string):\n",
    "    # Get Replacement rule\n",
    "    #rules_path = f\"rules/{master_data['source_lang']}_{master_data['target_lang']}.txt\"\n",
    "    #replacement_rule = []\n",
    "    #if os.path.exists(rules_path):\n",
    "    #    with open(rules_path, \"r\") as fp:\n",
    "    #        rules_raw = fp.readlines()\n",
    "    #    for rule in rules_raw:\n",
    "    #        tmp_split = rule.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    #        if(len(tmp_split)) >= 2:\n",
    "    #            replacement_rule.append([tmp_split[0], tmp_split[1]])\n",
    "\n",
    "    # split contents\n",
    "    sources, tmp = [], []\n",
    "    cnt = 0\n",
    "    for s in source_string.splitlines(keepends=True):\n",
    "        cnt += len(s)\n",
    "        if cnt > 4500:\n",
    "            sources.append(\"\".join(tmp))\n",
    "            tmp = [s]\n",
    "            cnt = len(s)\n",
    "        else:\n",
    "            tmp.append(s)\n",
    "    else:\n",
    "        sources.append(\"\".join(tmp))\n",
    "\n",
    "    # DeepL Translate\n",
    "    try:\n",
    "        translator = deepl.Translator(auth_key=master_data[\"auth_key\"])\n",
    "        result = translator.translate_text(\n",
    "                    [sources], \n",
    "                    source_lang=master_data[\"source_lang\"],\n",
    "                    target_lang=master_data[\"target_lang\"],\n",
    "                    tag_handling=\"xml\",\n",
    "                    ignore_tags=[\"keep\",\"keep2\"])\n",
    "        usage = translator.get_usage()\n",
    "        result_txt = \"\\n\".join([r.text for r in result])\n",
    "    except Exception as ex:\n",
    "        return \"\", \"DeepL translation error\\n\"+str(ex)\n",
    "\n",
    "    # ルールベースで置き換え\n",
    "    message = \"\"\n",
    "    #for rule in replacement_rule:\n",
    "    #    try:\n",
    "    #        #print(rule)\n",
    "    #        result_txt = re.sub(rule[0], rule[1], result_txt)\n",
    "    #    except Exception as ex:\n",
    "    #        message = f\"Replacement rule error at {rule[0]} -> {rule[1]}\\n\"+str(ex)\n",
    "    #\n",
    "    if message == \"\":\n",
    "        return result_txt, f\"Translate success\\nCharacter usage: {usage.character.count} of {usage.character.limit}\"\n",
    "    else:\n",
    "        return result_txt, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stringの読み込み\n",
    "source = \"../sample/test.md\"\n",
    "output_dir = \"../sample/output\"\n",
    "\n",
    "lines = []\n",
    "load_str = ''\n",
    "with open(f\"{source}\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()    # mdファイルの内容を1行ずつ配列に入れる\n",
    "load_str = ''.join(lines)    # 全行を取得後、配列を結合して文字列変数に入れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $aa$びように挟まれた場所を翻訳されないように、<keep>aaa</keep>で挟む。\n",
    "# いいやり方を思いつかなかったので、交互に変換する。ちゃんと交互になっていると信じる。\n",
    "for i in range(10000):\n",
    "    load_str = load_str.replace(r\"$\",r\"<keep>\",1)\n",
    "    load_str = load_str.replace(r\"$\",r\"</keep>\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$aa$$の場合は、<keep></keep>になってしまっているので、そこは<keep2>aaa</keep2>に変える。\n",
    "for i in range(1000):\n",
    "    load_str = load_str.replace(r\"<keep></keep>\",r\"<keep2>\",1)\n",
    "    load_str = load_str.replace(r\"<keep></keep>\",r\"</keep2>\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Workload-Aware Anonymization\\n\\nKristen LeFevre <keep>^{1} \\\\quad</keep> David J. DeWitt <keep>{ }^{1} \\\\quad</keep> Raghu Ramakrishnan <keep>{ }^{1,2}</keep><br><keep>{ }^{1}</keep> University of Wisconsin - Madison, 1210 West Dayton St., Madison, WI 53706<br><keep>{ }^{2}</keep> Yahoo! Research, 701 First Ave., Sunnyvale, CA 94089\\n\\n\\n#### Abstract\\n\\nProtecting data privacy is an important problem in microdata distribution. Anonymization algorithms typically aim to protect individual privacy, with minimal impact on the quality of the resulting data. While the bulk of previous work has measured quality through one-size-fits-all measures, we argue that quality is best judged with respect to the workload for which the data will ultimately be used.\\n\\nThis paper provides a suite of anonymization algorithms that produce an anonymous view based on a target class of workloads, consisting of one or more data mining tasks, as well as selection predicates. An extensive experimental evaluation indicates that this approach is often more effective than previous anonymization techniques.\\n\\n\\n### Single Target Classification Model\\n\\nThe Mondrian algorithm was recently proposed for kanonymization using multidimensional recoding [17]. The algorithm is based on a greedy recursive partitioning of the (multidimensional) quasi-identifier domain space (see Figure 3). In order to obtain approximately uniform partition occupancy, [17] suggests recursively choosing the split attribute with the largest normalized range of values, and (for continuous or ordinal attributes) partitioning the data around the median value of the split attribute. This process is repeated until no allowable split remains, meaning that a particular region cannot be further divided without violating the anonymity constraint, or constraints imposed by value generalization hierarchies. We refer to this algorithm as Median Mondrian.\\n\\nWhen the (set of) target mining model(s) is known, we can improve this heuristic. First consider a single target classification model, with predictor attributes <keep>Q_{1}, \\\\ldots, Q_{d}</keep> (also the quasi-identifier) and class label <keep>C</keep>. In this case, we propose a heuristic partitioning scheme based on information gain, which is reminiscent of decision tree construction. Intuitively, the goal of this greedy criterion is to produce homogeneous partitions of class labels.\\n\\nAt each recursive step, we choose the split that minimizes the weighted entropy over the set of resulting partitions (without violating the anonymity constraint). <keep>P</keep> denotes the current (recursive) tuple set, and partitions <keep>P^{\\\\prime}</keep> denotes the set of partitions resulting from the candidate split. <keep>p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)</keep> is the fraction of tuples in <keep>P^{\\\\prime}</keep> with class label <keep>C=c</keep>. We refer to this algorithm as InfoGain Mondrian.\\n\\n<keep2>\\n\\\\operatorname{Entropy}(P, C)=\\\\sum_{\\\\text {partitions } P^{\\\\prime}} \\\\frac{\\\\left|P^{\\\\prime}\\\\right|}{|P|} \\\\sum_{c \\\\in D_{C}}-p\\\\left(c \\\\mid P^{\\\\prime}\\\\right) \\\\log p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)\\n</keep2>\\n\\nInfoGain Mondrian handles continuous quasi-identifier values as they are typically handled by decision-trees, partitioning around the threshold value with smallest entropy (see [12]). The data is first sorted with respect to the split attribute. Then the data is scanned, and each time there is a change in class label, this candidate threshold is checked with respect to anonymity and entropy. In the event that no candidate threshold satisfies the anonymity constraint, the median is also checked as a default\\n\\nInfoGain Mondrian scales to large data sets through a straightforward adaptation of an existing scalable decisiontree induction scheme, such as RainForest [14].\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/middle.md\", mode=\"w\") as f:\n",
    "    f.write(load_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_txt, message = translate(load_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "result_ = deepcopy(result_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# ワークロードを考慮した匿名化\\n\\nKristen LeFevre<keep>^{1} \\\\quad</keep> David J. DeWitt<keep>{ }^{1} \\\\quad</keep> Raghu Ramakrishnan<keep>{ }^{1,2}</keep><br> <keep>{ }^{1}</keep> University of Wisconsin - Madison, 1210 West Dayton St., Madison, WI 53706<br><keep>{ }^{2}</keep> Yahoo! Research, 701 First Ave., Sunnyvale, CA 94089\\n\\n\\n#### 要旨\\n\\nデータのプライバシー保護は、マイクロデータの配布において重要な問題である。匿名化アルゴリズムは通常、個人のプライバシーを保護し、結果として得られるデータの品質への影響を最小限に抑えることを目的としている。これまでの研究の大部分は、一律に品質を測定してきたが、我々は、品質とは、データが最終的に使用される作業負荷に関して最もよく判断されるものであると主張する。\\n\\n本論文では、1つまたは複数のデータマイニングタスクと選択述語からなる作業負荷のターゲットクラスに基づいて匿名化ビューを生成する一連の匿名化アルゴリズムを提供します。広範な実験的評価により、このアプローチは、これまでの匿名化技術よりもしばしば効果的であることが示された。\\n\\n\\n### 単一ターゲット分類モデル\\n\\n多次元再符号化を用いた匿名化のために、Mondrianアルゴリズムが最近提案された[17]。このアルゴリズムは、（多次元）準識別子領域空間の貪欲な再帰的分割に基づく（図3参照）。ほぼ均一なパーティション占有率を得るために、[17]は、正規化された値の範囲が最大の分割属性を再帰的に選択し、（連続または順序属性の場合）分割属性の中央値を中心にデータをパーティション化することを提案している。このプロセスは、許容される分割がなくなるまで繰り返される。つまり、匿名性の制約や値の汎化階層によって課される制約に違反しない限り、特定の領域をさらに分割することができないことを意味している。このアルゴリズムをMedian Mondrianと呼ぶ。\\n\\nターゲットマイニングモデル（のセット）がわかっている場合、このヒューリスティックを改良することができる。まず、予測属性<keep>Q_{1}, \\\\ldots, Q_{d}</keep> （準識別子でもある）とクラスラベル<keep>C</keep> を持つ、単一のターゲット分類モデルを考える。この場合、情報利得に基づく発見的な分割スキームを提案するが、これは決定木の構築を連想させる。直感的には、この貪欲な基準の目標は、クラスラベルの均質なパーティションを生成することである。\\n\\n各再帰ステップで、（匿名性制約に違反することなく）結果のパーティションセットに対する重み付けエントロピーを最小化する分割を選択する。<keep>P</keep> は現在の（再帰的）タプルセットを示し、パーティション<keep>P^{\\\\prime}</keep> は候補分割から得られるパーティションのセットを示す。<keep>p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)</keep> は<keep>P^{\\\\prime}</keep> のタプルのうちクラスラベル<keep>C=c</keep> を持つ割合である。このアルゴリズムをInfoGain Mondrianと呼ぶことにする。\\n\\n<keep2>\\n\\\\operatorname{Entropy}(P, C)=\\\\sum_{\\\\text {partitions } P^{\\\\prime}} \\\\frac{\\\\left|P^{\\\\prime}\\\\right|}{|P|} \\\\sum_{c \\\\in D_{C}}-p\\\\left(c \\\\mid P^{\\\\prime}\\\\right) \\\\log p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)\\n</keep2>\\n\\nInfoGain Mondrianは、決定木で一般的に扱われるように、連続した準識別値を扱い、最小のエントロピーを持つ閾値を中心にパーティショニングを行います（[12]を参照）。データはまず、分割された属性に関してソートされる。その後、データをスキャンし、クラスラベルに変化があるたびに、匿名性とエントロピーに関してこの閾値候補をチェックする。匿名性の制約を満たす閾値候補がない場合、デフォルトとして中央値もチェックされる。\\n\\nInfoGain Mondrianは、RainForest [14]のような既存のスケーラブルな決定木誘導スキームをそのまま適応することで、大規模なデータセットにスケールします。\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ = re.sub(r\"<keep>\",r\" \\$\\$\", result_)\n",
    "result_ = re.sub(r\"</keep>\", r\"\\$ \",result_)\n",
    "result_ = re.sub(r\"<keep2>\", r\"$$\\n\\\\begin{align*}\", result_)\n",
    "result_ = re.sub(r\"</keep2>\", r\"\\\\end{align*}\\n$$\", result_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# ワークロードを考慮した匿名化\\n\\nKristen LeFevre \\\\$\\\\$^{1} \\\\quad\\\\$  David J. DeWitt \\\\$\\\\${ }^{1} \\\\quad\\\\$  Raghu Ramakrishnan \\\\$\\\\${ }^{1,2}\\\\$ <br>  \\\\$\\\\${ }^{1}\\\\$  University of Wisconsin - Madison, 1210 West Dayton St., Madison, WI 53706<br> \\\\$\\\\${ }^{2}\\\\$  Yahoo! Research, 701 First Ave., Sunnyvale, CA 94089\\n\\n\\n#### 要旨\\n\\nデータのプライバシー保護は、マイクロデータの配布において重要な問題である。匿名化アルゴリズムは通常、個人のプライバシーを保護し、結果として得られるデータの品質への影響を最小限に抑えることを目的としている。これまでの研究の大部分は、一律に品質を測定してきたが、我々は、品質とは、データが最終的に使用される作業負荷に関して最もよく判断されるものであると主張する。\\n\\n本論文では、1つまたは複数のデータマイニングタスクと選択述語からなる作業負荷のターゲットクラスに基づいて匿名化ビューを生成する一連の匿名化アルゴリズムを提供します。広範な実験的評価により、このアプローチは、これまでの匿名化技術よりもしばしば効果的であることが示された。\\n\\n\\n### 単一ターゲット分類モデル\\n\\n多次元再符号化を用いた匿名化のために、Mondrianアルゴリズムが最近提案された[17]。このアルゴリズムは、（多次元）準識別子領域空間の貪欲な再帰的分割に基づく（図3参照）。ほぼ均一なパーティション占有率を得るために、[17]は、正規化された値の範囲が最大の分割属性を再帰的に選択し、（連続または順序属性の場合）分割属性の中央値を中心にデータをパーティション化することを提案している。このプロセスは、許容される分割がなくなるまで繰り返される。つまり、匿名性の制約や値の汎化階層によって課される制約に違反しない限り、特定の領域をさらに分割することができないことを意味している。このアルゴリズムをMedian Mondrianと呼ぶ。\\n\\nターゲットマイニングモデル（のセット）がわかっている場合、このヒューリスティックを改良することができる。まず、予測属性 \\\\$\\\\$Q_{1}, \\\\ldots, Q_{d}\\\\$  （準識別子でもある）とクラスラベル \\\\$\\\\$C\\\\$  を持つ、単一のターゲット分類モデルを考える。この場合、情報利得に基づく発見的な分割スキームを提案するが、これは決定木の構築を連想させる。直感的には、この貪欲な基準の目標は、クラスラベルの均質なパーティションを生成することである。\\n\\n各再帰ステップで、（匿名性制約に違反することなく）結果のパーティションセットに対する重み付けエントロピーを最小化する分割を選択する。 \\\\$\\\\$P\\\\$  は現在の（再帰的）タプルセットを示し、パーティション \\\\$\\\\$P^{\\\\prime}\\\\$  は候補分割から得られるパーティションのセットを示す。 \\\\$\\\\$p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)\\\\$  は \\\\$\\\\$P^{\\\\prime}\\\\$  のタプルのうちクラスラベル \\\\$\\\\$C=c\\\\$  を持つ割合である。このアルゴリズムをInfoGain Mondrianと呼ぶことにする。\\n\\n$$\\n\\\\begin{align*}\\n\\\\operatorname{Entropy}(P, C)=\\\\sum_{\\\\text {partitions } P^{\\\\prime}} \\\\frac{\\\\left|P^{\\\\prime}\\\\right|}{|P|} \\\\sum_{c \\\\in D_{C}}-p\\\\left(c \\\\mid P^{\\\\prime}\\\\right) \\\\log p\\\\left(c \\\\mid P^{\\\\prime}\\\\right)\\n\\\\end{align*}\\n$$\\n\\nInfoGain Mondrianは、決定木で一般的に扱われるように、連続した準識別値を扱い、最小のエントロピーを持つ閾値を中心にパーティショニングを行います（[12]を参照）。データはまず、分割された属性に関してソートされる。その後、データをスキャンし、クラスラベルに変化があるたびに、匿名性とエントロピーに関してこの閾値候補をチェックする。匿名性の制約を満たす閾値候補がない場合、デフォルトとして中央値もチェックされる。\\n\\nInfoGain Mondrianは、RainForest [14]のような既存のスケーラブルな決定木誘導スキームをそのまま適応することで、大規模なデータセットにスケールします。\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/result2.md\", mode=\"w\") as f:\n",
    "    f.write(result_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
